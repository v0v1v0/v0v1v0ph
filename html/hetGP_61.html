<div class="container">

<table style="width: 100%;"><tr>
<td>ato</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Assemble To Order (ATO) Data and Fits </h2>

<h3>Description</h3>

<p>A batch design-evaluated ATO data set, random partition into training and
testing, and fitted <span class="pkg">hetGP</span> model; similarly a sequentially designed
adaptive horizon data set, and associated fitted <span class="pkg">hetGP</span> model 
</p>


<h3>Usage</h3>

<pre><code class="language-R">data(ato)</code></pre>


<h3>Format</h3>

<p>Calling <code>data(ato)</code> causes the following objects to be loaded into the namespace.
</p>

<dl>
<dt><code>X</code></dt>
<dd>
<p> 2000x8 <code>matrix</code> of inputs coded from 1,...,20 to the unit 8-cube; original inputs can be recreated as <code>X*19 + 1</code> </p>
</dd>
<dt><code>Z</code></dt>
<dd>
<p> 2000x10 <code>matrix</code> of normalized outputs obtained in ten replicates at each of the 2000 inputs <code>X</code>.  Original outputs can be obtained as <code>Z*sqrt(Zv) + Zm</code> </p>
</dd>
<dt><code>Zm</code></dt>
<dd>
<p> scalar mean used to normalize <code>Z</code> </p>
</dd>
<dt><code>Zv</code></dt>
<dd>
<p> scalar variance used to normalize <code>Z</code> </p>
</dd>
<dt><code>train</code></dt>
<dd>
<p> vector of 1000 rows of <code>X</code> and <code>Z</code> selected for training </p>
</dd>
<dt><code>Xtrain</code></dt>
<dd>
<p> 1000x8 <code>matrix</code> obtained as a random partition of <code>X</code> </p>
</dd>
<dt><code>Ztrain</code></dt>
<dd>
<p> length 1000 list of vectors containing the selected (replicated) observations at each row of <code>Xtrain</code> </p>
</dd>
<dt><code>mult</code></dt>
<dd>
<p> the length of each entry of <code>Ztrain</code>; same as <code>unlist(lapply(Ztrain, length))</code> </p>
</dd>
<dt><code>kill</code></dt>
<dd>
<p> a <code>logical</code> vector indicating which rows of <code>Xtrain</code> for which all replicates of <code>Z</code> are selected for <code>Ztrain</code>;  same as <code>mult == 10</code></p>
</dd>
<dt><code>Xtrain.out</code></dt>
<dd>
<p> 897x8 <code>matrix</code> comprised of the subset of <code>X</code> where not all replicates are selected for training; i.e., those for which <code>kill == FALSE</code> </p>
</dd>
<dt><code>Ztrain.out</code></dt>
<dd> <p><code>list</code> of length 897 containing the replicates of <code>Z</code> not selected for <code>Ztrain</code> </p>
</dd>
<dt><code>nc</code></dt>
<dd> <p><code>noiseControl</code> argument for <code>mleHetGP</code> call </p>
</dd>
<dt><code>out</code></dt>
<dd> <p><code>mleHetGP</code> model based on <code>Xtrain</code> and <code>Ztrain</code> using <code>noiseControl=nc</code> </p>
</dd>
<dt><code>Xtest</code></dt>
<dd>
<p> 1000x8 <code>matrix</code> containing the other partition of <code>X</code> of locations not selected for training </p>
</dd>
<dt><code>Ztest</code></dt>
<dd>
<p> 1000x10 <code>matrix</code> of responses from the partition of <code>Z</code> not selected for training </p>
</dd>
<dt><code>ato.a</code></dt>
<dd>
<p> 2000x9 <code>matrix</code> of sequentially designed inputs (8) and outputs (1) obtained under an adaptive horizon scheme </p>
</dd>
<dt><code>Xa</code></dt>
<dd>
<p> 2000x8 matrix of coded inputs from <code>ato.a</code> as <code>(ato.a[,1:8]-1)/19</code> </p>
</dd>
<dt><code>Za</code></dt>
<dd>
<p> length 2000 vector of outputs from <code>ato.a</code> as <code>(ato.a[,9] - Zm)/sqrt(Zv)</code> </p>
</dd>
<dt><code>out.a</code></dt>
<dd> <p><code>mleHetGP</code> model based on <code>Xa</code> and <code>Za</code> using <code>noiseControl=nc</code> </p>
</dd>
</dl>
<h3>Details</h3>

<p>The assemble to order (ATO) simulator  (Hong, Nelson, 2006) is a queuing
simulation targeting inventory management scenarios.  The setup is as follows.
A company manufactures <code class="reqn">m</code> products.  Products are built from base parts
called items, some of which are “key” in that the product cannot be built
without them.  If a random request comes in for a product that is missing a
key item, a replenishment order is executed, and is filled after a random
period.  Holding items in inventory is expensive, so there is a balance
between inventory costs and revenue. Hong &amp; Nelson built a
<code>Matlab</code> simulator for this setup, which was subsequently
reimplemented by Xie, et al., (2012).  
</p>
<p>Binois, et al (2018a) describe an out-of-sample experiment based on this
latter implementation in its default (Hong &amp; Nelson) setting, specifying
item cost structure, product makeup (their items) and revenue, distribution
of demand and replenishment time, under target stock vector inputs <code class="reqn">b \in
  \{1,\dots,20\}^8</code> for eight items.  They worked with 2000
random uniform input locations (<code>X</code>), and ten replicate responses at
each location (<code>Z</code>). The partition of 1000 training data points
(<code>Xtrain</code> and
<code>Ztrain</code>) and 1000 testing (<code>Xtest</code> and <code>Ztest</code>) sets
provided here is an example of one that was used for the Monte Carlo
experiment in that paper.  The elements <code>Xtrain.out</code> and
<code>Ztrain.out</code> comprise of replicates from the training inputs which were
not used in training, so may be used for out-of-sample testing.  For more
details on how the partitions were build, see the code in the examples
section below.
</p>
<p>Binois, et al (2018b) describe an adaptive lookahead horizon scheme for
building a sequential design (<code>Xa</code>, <code>Za</code>) of size 2000 whose
predictive performance, via proper scores, is almost as good as the
approximately 5000 training data sites in each of the Monte Carlo
repetitions described above.  The example code below demonstrates this via
out-of-sample predictions on <code>Xtest</code> (measured against <code>Ztest</code>)
when <code>Xtrain</code> and <code>Ztrain</code> are used compared to those from
<code>Xa</code> and <code>Za</code>.
</p>


<h3>Note</h3>

<p> The <code>mleHetGP</code> output objects were build with
<code>return.matrices=FALSE</code> for more compact storage.  Before these objects
can be used for calculations, e.g., prediction or design, these covariance
matrices need to be rebuilt with <code>rebuild</code>.  The generic
<code>predict</code> method will call <code>rebuild</code> automatically, 
however, some of the other methods will not, and it is often more
efficient to call <code>rebuild</code> once at the outset, rather
than for every subsequent <code>predict</code> call </p>


<h3>Author(s)</h3>

 
<p>Mickael Binois, <a href="mailto:mbinois@mcs.anl.gov">mbinois@mcs.anl.gov</a>, and
Robert B. Gramacy, <a href="mailto:rbg@vt.edu">rbg@vt.edu</a>
</p>


<h3>References</h3>

<p>Hong L., Nelson B. (2006), Discrete optimization via simulation using COMPASS. Operations Research, 54(1), 115-129.
</p>
<p>Xie J., Frazier P., Chick S. (2012). Assemble to Order Simulator. <a href="https://web.archive.org/web/20210308024531/http://simopt.org/wiki/index.php?title=Assemble_to_Order&amp;oldid=447">https://web.archive.org/web/20210308024531/http://simopt.org/wiki/index.php?title=Assemble_to_Order&amp;oldid=447</a>.
</p>
<p>M. Binois, J. Huang, R. Gramacy, M. Ludkovski (2018a), Replication or exploration? Sequential design for stochastic simulation experiments,
arXiv preprint arXiv:1710.03206.
</p>
<p>M. Binois, Robert B. Gramacy, M. Ludkovski (2018b), Practical heteroskedastic Gaussian process modeling for large simulation experiments,
arXiv preprint arXiv:1611.05902.
</p>


<h3>See Also</h3>

 <p><code>bfs</code>, <code>sirEval</code>, <code>link{rebuild}</code>, 
<code>horizon</code>, <code>IMSPE_optim</code>, <code>mleHetGP</code>, 
<code>vignette("hetGP")</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">data(ato)

## Not run: 
##
## the code below was used to create the random partition 
##

## recover the data in its original form
X &lt;- X*19+1
Z &lt;- Z*sqrt(Zv) + Zm

## code the inputs and outputs; i.e., undo the transformation 
## above
X &lt;- (X-1)/19
Zm &lt;- mean(Z)
Zv &lt;- var(as.vector(Z))
Z &lt;- (Z - Zm)/sqrt(Zv)

## random training and testing partition
train &lt;- sample(1:nrow(X), 1000)
Xtrain &lt;- X[train,]
Xtest &lt;- X[-train,]
Ztest &lt;- as.list(as.data.frame(t(Z[-train,])))
Ztrain &lt;- Ztrain.out &lt;- list()
mult &lt;- rep(NA, nrow(Xtrain))
kill &lt;- rep(FALSE, nrow(Xtrain))
for(i in 1:length(train)) {
  reps &lt;- sample(1:ncol(Z), 1)
  w &lt;- sample(1:ncol(Z), reps)
  Ztrain[[i]] &lt;- Z[train[i],w]
  if(reps &lt; 10) Ztrain.out[[i]] &lt;- Z[train[i],-w]
  else kill[i] &lt;- TRUE
  mult[i] &lt;- reps
}

## calculate training locations and outputs for replicates not
## included in Ztrain
Xtrain.out &lt;- Xtrain[!kill,]
Ztrain.out &lt;- Ztrain[which(!kill)]

## fit hetGP model
out &lt;- mleHetGP(X=list(X0=Xtrain, Z0=sapply(Ztrain, mean), mult=mult),
  Z=unlist(Ztrain), lower=rep(0.01, ncol(X)), upper=rep(30, ncol(X)),
  covtype="Matern5_2", noiseControl=nc, known=list(beta0=0), 
  maxit=100000, settings=list(return.matrices=FALSE))

##
## the adaptive lookahead design is read in and fit as 
## follows
##
Xa &lt;- (ato.a[,1:8]-1)/19
Za &lt;- ato.a[,9]
Za &lt;- (Za - Zm)/sqrt(Zv)

## uses nc defined above
out.a &lt;- mleHetGP(Xa, Za, lower=rep(0.01, ncol(X)), 
  upper=rep(30, ncol(X)), covtype="Matern5_2", known=list(beta0=0), 
  noiseControl=nc, maxit=100000, settings=list(return.matrices=FALSE))

## End(Not run)

##
## the following code duplicates a predictive comparison in
## the package vignette
##

## first using the model fit to the train partition (out)
out &lt;- rebuild(out)

## predicting out-of-sample at the test sights
phet &lt;- predict(out, Xtest)
phets2 &lt;- phet$sd2 + phet$nugs
mhet &lt;- as.numeric(t(matrix(rep(phet$mean, 10), ncol=10)))
s2het &lt;- as.numeric(t(matrix(rep(phets2, 10), ncol=10)))
sehet &lt;- (unlist(t(Ztest)) - mhet)^2
sc &lt;- - sehet/s2het - log(s2het)
mean(sc)

## predicting at the held-out training replicates
phet.out &lt;- predict(out, Xtrain.out)
phets2.out &lt;- phet.out$sd2 + phet.out$nugs
s2het.out &lt;- mhet.out &lt;- Ztrain.out
for(i in 1:length(mhet.out)) {
  mhet.out[[i]] &lt;- rep(phet.out$mean[i], length(mhet.out[[i]]))
  s2het.out[[i]] &lt;- rep(phets2.out[i], length(s2het.out[[i]]))
}
mhet.out &lt;- unlist(t(mhet.out))
s2het.out &lt;- unlist(t(s2het.out))
sehet.out &lt;- (unlist(t(Ztrain.out)) - mhet.out)^2
sc.out &lt;- - sehet.out/s2het.out - log(s2het.out)
mean(sc.out)

## Not run: 
## then using the model trained from the "adaptive" 
## sequential design, with comparison from the "batch" 
## one above, using the scores function
out.a &lt;- rebuild(out.a)
sc.a &lt;- scores(out.a, Xtest = Xtest, Ztest = Ztest)
c(batch=mean(sc), adaptive=sc.a)

## an example of one iteration of sequential design

  Wijs &lt;- Wij(out.a$X0, theta=out.a$theta, type=out.a$covtype)
  h &lt;- horizon(out.a, Wijs=Wijs)
  control = list(tol_dist=1e-4, tol_diff=1e-4, multi.start=30, maxit=100)
  opt &lt;- IMSPE_optim(out.a, h, Wijs=Wijs, control=control)
  opt$par

## End(Not run)
</code></pre>


</div>