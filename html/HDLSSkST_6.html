<div class="container">

<table style="width: 100%;"><tr>
<td>gMADD</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Modified K-Means Algorithm by Using a New Dissimilarity Measure, MADD
</h2>

<h3>Description</h3>

<p>Performs modified K-means algorithm by using a new dissimilarity measure, called MADD, and provides estimated cluster (class) labels or memberships of observations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gMADD(s_psi, s_h, n_clust, lb, M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>s_psi</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">t^2</code>, 2 for <code class="reqn">1-\exp(-t)</code>, 3 for <code class="reqn">1-\exp(-t^2)</code>, 4 for <code class="reqn">\log(1+t)</code>, 5 for <code class="reqn">t</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s_h</code></td>
<td>

<p>function required for clustering, 1 for <code class="reqn">\sqrt t</code>, 2 for <code class="reqn">t</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_clust</code></td>
<td>

<p>total number of the classes in the whole observations
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lb</code></td>
<td>

<p>each observation is partitioned into some numbers of smaller vectors of same length <code class="reqn">lb</code> 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>

<p><code class="reqn">n\times d</code> observations matrix of pooled sample, the observations should be grouped by their respective classes
</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a vector of length n of estimated cluster (class) labels of observations
</p>


<h3>Author(s)</h3>

<p> Biplab Paul, Shyamal K. De and Anil K. Ghosh
</p>
<p>Maintainer: Biplab Paul&lt;paul.biplab497@gmail.com&gt;
</p>


<h3>References</h3>

<p>Biplab Paul, Shyamal K De and Anil K Ghosh (2021).  Some clustering based exact distribution-free k-sample tests
applicable to high dimension, low sample size data, <em>Journal of Multivariate Analysis</em>, doi:10.1016/j.jmva.2021.104897.
</p>
<p>Soham Sarkar and Anil K Ghosh (2019). On perfect clustering of high dimension, low sample size data, <em>IEEE transactions on pattern analysis and machine intelligence</em>, doi:10.1109/TPAMI.2019.2912599.
</p>


<h3>Examples</h3>

<pre><code class="language-R">  # Modified K-means algorithm:
  # muiltivariate normal distribution
  # generate data with dimension d = 500
  set.seed(151)
  n1=n2=n3=n4=10
  d = 500
  I1 &lt;- matrix(rnorm(n1*d,mean=0,sd=1),n1,d)
  I2 &lt;- matrix(rnorm(n2*d,mean=0.5,sd=1),n2,d) 
  I3 &lt;- matrix(rnorm(n3*d,mean=1,sd=1),n3,d) 
  I4 &lt;- matrix(rnorm(n4*d,mean=1.5,sd=1),n4,d) 
  n_cl &lt;- 4
  X &lt;- as.matrix(rbind(I1,I2,I3,I4)) 
  gMADD(1,1,n_cl,1,X)
  
   ## outputs:
   #[1] 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3
</code></pre>


</div>