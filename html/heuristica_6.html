<div class="container">

<table style="width: 100%;"><tr>
<td>confusionMatrixFor_Neg1_0_1</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Confusion matrix for categories -1, 0, 1 (the output of predictPair).</h2>

<h3>Description</h3>

<p>Measuring accuracy of predicting categories, where in the predictPair paradigm
the categories are the relative ranks of a pair of rows.  The categories are:
-1 means Row1 &lt; Row2
0 means the rows are equal or guess
1 means Row1 &gt; Row2
</p>


<h3>Usage</h3>

<pre><code class="language-R">confusionMatrixFor_Neg1_0_1(ref_data, predicted_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ref_data</code></td>
<td>
<p>A vector with outcome categories from a reference source to
be predicted (e.g. the output of correctGreater.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>predicted_data</code></td>
<td>
<p>A vector with outcome categories from a prediction
source that is trying to match ref_data (e.g. ttbModel predictions).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A 3x3 matrix of counts.  Rows are outcomes of the reference data.
Columns are outcomes of predicted data.
</p>


<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Confusion_matrix">https://en.wikipedia.org/wiki/Confusion_matrix</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Example 1
# Below, the correct outcome is always 1, so only the last row of the
# confusion matrix has non-zero counts.  But the predictor makes a few
# mistakes, so some non-zero counts are off the diagonal.
confusionMatrixFor_Neg1_0_1(c(1,1,1), c(1,-1,-1))
# outputs:
#    -1 0 1
# -1  0 0 0
# 0   0 0 0
# 1   2 0 1
#
# Example 2
# The prediction always matches the reference outcome, so all non-zero
# counts are on the diagonal.
confusionMatrixFor_Neg1_0_1(c(1,1,0,0,-1,-1), c(1,1,0,0,-1,-1))
# outputs:
#    -1 0 1
# -1  2 0 0
# 0   0 2 0
# 1   0 0 2
#
</code></pre>


</div>