<div class="container">

<table style="width: 100%;"><tr>
<td>htlr_prior</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generate Prior Configuration</h2>

<h3>Description</h3>

<p>Configure prior hyper-parameters for HTLR model fitting
</p>


<h3>Usage</h3>

<pre><code class="language-R">htlr_prior(
  ptype = c("t", "ghs", "neg"),
  df = 1,
  logw = -(1/df) * 10,
  eta = ifelse(df &gt; 1, 3, 0),
  sigmab0 = 2000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>ptype</code></td>
<td>
<p>The prior to be applied to the model. Either "t" (student-t, default), "ghs" (horseshoe), 
or "neg" (normal-exponential-gamma).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>The degree freedom (aka alpha) of t/ghs/neg prior for coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>logw</code></td>
<td>
<p>The log scale of priors for coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eta</code></td>
<td>
<p>The <code>sd</code> of the normal prior for logw. When it is set to 0, logw is fixed. 
Otherwise, logw is assigned with a normal prior and it will be updated during sampling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigmab0</code></td>
<td>
<p>The <code>sd</code> of the normal prior for the intercept.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The output is a configuration list which is to be passed to <code>prior</code> argument of <code>htlr</code>.     
For naive users, you only need to specify the prior type and degree freedom, then the other hyper-parameters
will be chosen automatically. For advanced users, you can supply each prior hyper-parameters by yourself.
For suggestion of picking hyper-parameters, see <code>references</code>.
</p>


<h3>Value</h3>

<p>A configuration list containing <code>ptype</code>, <code>alpha</code>, <code>logw</code>, <code>eta</code>, and <code>sigmab0</code>.
</p>


<h3>References</h3>

<p>Longhai Li and Weixin Yao. (2018). Fully Bayesian Logistic Regression 
with Hyper-Lasso Priors for High-dimensional Feature Selection.
<em>Journal of Statistical Computation and Simulation</em> 2018, 88:14, 2827-2851.
</p>


</div>