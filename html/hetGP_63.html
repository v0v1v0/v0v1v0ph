<div class="container">

<table style="width: 100%;"><tr>
<td>update.hetTP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Update <code>"hetTP"</code>-class model fit with new observations</h2>

<h3>Description</h3>

<p>Fast update of existing <code>hetTP</code> model with new observations.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'hetTP'
update(
  object,
  Xnew,
  Znew,
  ginit = 0.01,
  lower = NULL,
  upper = NULL,
  noiseControl = NULL,
  settings = NULL,
  known = NULL,
  maxit = 100,
  method = "quick",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>previously fit <code>"hetTP"</code>-class model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xnew</code></td>
<td>
<p>matrix of new design locations; <code>ncol(Xnew)</code> must match the input dimension encoded in <code>object</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Znew</code></td>
<td>
<p>vector new observations at those design locations, of length <code>nrow(X)</code>. <code>NA</code>s can be passed, see Details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ginit</code></td>
<td>
<p>minimal value of the smoothing parameter (i.e., nugget of the noise process) for optimization initialisation.
It is compared to the <code>g</code> hyperparameter in the object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lower, upper, noiseControl, settings, known</code></td>
<td>
<p>optional bounds for mle optimization, see <code>mleHetTP</code>. 
If not provided, they are extracted from the existing model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxit</code></td>
<td>
<p>maximum number of iterations for the internal L-BFGS-B optimization method; see <code>optim</code> for more details</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>one of <code>"quick"</code>, <code>"mixed"</code> see Details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>no other argument for this method.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The update can be performed with or without re-estimating hyperparameter.
In the first case, <code>mleHetTP</code> is called, based on previous values for initialization. 
The only missing values are the latent variables at the new points, that are initialized based on two possible update schemes in <code>method</code>:
</p>

<ul>
<li> <p><code>"quick"</code> the new delta value is the predicted nugs value from the previous noise model;
</p>
</li>
<li> <p><code>"mixed"</code> new values are taken as the barycenter between prediction given by the noise process and empirical variance. 
</p>
</li>
</ul>
<p>The subsequent number of MLE computations can be controlled with <code>maxit</code>.
</p>
<p>In case hyperparameters need not be updated, <code>maxit</code> can be set to <code>0</code>. 
In this case it is possible to pass <code>NA</code>s in <code>Znew</code>, then the model can still be used to provide updated variance predictions.
</p>


<h3>Examples</h3>

<pre><code class="language-R">##------------------------------------------------------------
## Sequential update example
##------------------------------------------------------------
set.seed(42)

## Spatially varying noise function
noisefun &lt;- function(x, coef = 1){
  return(coef * (0.05 + sqrt(abs(x)*20/(2*pi))/10))
}

## Initial data set
nvar &lt;- 1
n &lt;- 20
X &lt;- matrix(seq(0, 2 * pi, length=n), ncol = 1)
mult &lt;- sample(1:10, n, replace = TRUE)
X &lt;- rep(X, mult)
Z &lt;- sin(X) + noisefun(X) * rt(length(X), df = 10)

## Initial fit
testpts &lt;- matrix(seq(0, 2*pi, length = 10*n), ncol = 1)
model &lt;- model_init &lt;- mleHetTP(X = X, Z = Z, lower = rep(0.1, nvar), 
  upper = rep(50, nvar), maxit = 1000)

## Visualizing initial predictive surface
preds &lt;- predict(x = testpts, model_init) 
plot(X, Z)
lines(testpts, preds$mean, col = "red")

## 10 fast update steps
nsteps &lt;- 5
npersteps &lt;- 10
for(i in 1:nsteps){
  newIds &lt;- sort(sample(1:(10*n), npersteps))
  
  newX &lt;- testpts[newIds, drop = FALSE] 
  newZ &lt;- sin(newX) + noisefun(newX) * rt(length(newX), df = 10)
  points(newX, newZ, col = "blue", pch = 20)
  model &lt;- update(object = model, Xnew = newX, Znew = newZ)
  X &lt;- c(X, newX)
  Z &lt;- c(Z, newZ)
  plot(X, Z)
  print(model$nit_opt)
}

## Final predictions after 10 updates
p_fin &lt;- predict(x=testpts, model) 

## Visualizing the result by augmenting earlier plot
lines(testpts, p_fin$mean, col = "blue")
lines(testpts, qnorm(0.05, p_fin$mean, sqrt(p_fin$sd2)), col = "blue", lty = 2)
lines(testpts, qnorm(0.95, p_fin$mean, sqrt(p_fin$sd2)), col = "blue", lty = 2)
lines(testpts, qnorm(0.05, p_fin$mean, sqrt(p_fin$sd2 + p_fin$nugs)), 
  col = "blue", lty = 3)
lines(testpts, qnorm(0.95, p_fin$mean, sqrt(p_fin$sd2 + p_fin$nugs)), 
  col = "blue", lty = 3)

## Now compare to what you would get if you did a full batch fit instead
model_direct &lt;-  mleHetTP(X = X, Z = Z, maxit = 1000,
                          lower = rep(0.1, nvar), upper = rep(50, nvar),
                          init = list(theta = model_init$theta, k_theta_g = model_init$k_theta_g))
p_dir &lt;- predict(x = testpts, model_direct)
print(model_direct$nit_opt)
lines(testpts, p_dir$mean, col = "green")
lines(testpts, qnorm(0.05, p_dir$mean, sqrt(p_dir$sd2)), col = "green", 
  lty = 2)
lines(testpts, qnorm(0.95, p_dir$mean, sqrt(p_dir$sd2)), col = "green", 
  lty = 2)
lines(testpts, qnorm(0.05, p_dir$mean, sqrt(p_dir$sd2 + p_dir$nugs)), 
  col = "green", lty = 3)
lines(testpts, qnorm(0.95, p_dir$mean, sqrt(p_dir$sd2 + p_dir$nugs)), 
  col = "green", lty = 3)
lines(testpts, sin(testpts), col = "red", lty = 2)

## Compare outputs
summary(model_init)
summary(model)
summary(model_direct)

</code></pre>


</div>