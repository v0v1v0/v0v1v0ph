<div class="container">

<table style="width: 100%;"><tr>
<td>KMHFA</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Estimating the Pair of Factor Numbers via Eigenvalue Ratios or Rank Minimization.
</h2>

<h3>Description</h3>

<p>The function is to estimate the pair of factor numbers via eigenvalue-ratio corresponding to RMFA method or rank minimization and eigenvalue-ratio corresponding to Iterative Huber Regression (IHR). 
</p>


<h3>Usage</h3>

<pre><code class="language-R">KMHFA(X, W1 = NULL, W2 = NULL, kmax, method, max_iter = 100, c = 1e-04, ep = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>Input an array with <code class="reqn">T \times p_1 \times p_2</code>, where <code class="reqn">T</code> is the sample size, <code class="reqn">p_1</code> is the the row dimension of each matrix observation and <code class="reqn">p_2</code> is the the column dimension of each matrix observation.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>W1</code></td>
<td>

<p>Only if <code>method="E_RM"</code> or <code>method="E_ER"</code>, the inital value of row loadings matrix. The default is NULL, which is randomly chosen and all entries from a standard normal distribution.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>W2</code></td>
<td>

<p>Only if <code>method="E_RM"</code> or <code>method="E_ER"</code>, the inital value of column loadings matrix. The default is NULL, which is randomly chosen and all entries from a standard normal distribution.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kmax</code></td>
<td>

<p>The user-supplied maximum factor numbers. Here it means the upper bound of the number of row factors and column factors.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>

<p>Character string, specifying the type of the estimation method to be used.
</p>

<dl>
<dt><code>"P",</code></dt>
<dd>
<p>the robust iterative eigenvalue-ratio based on RMFA</p>
</dd>
<dt><code>"E_RM",</code></dt>
<dd>
<p>the rank-minimization based on IHR</p>
</dd>
<dt><code>"E_ER",</code></dt>
<dd>
<p>the eigenvalue-ratio based on IHR</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_iter</code></td>
<td>

<p>Only if <code>method="E_RM"</code> or <code>method="E_ER"</code>, the maximum number of iterations in the iterative Huber regression algorithm. The default is 100.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>c</code></td>
<td>

<p>A constant to avoid vanishing denominators. The default is <code class="reqn">10^{-4}</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ep</code></td>
<td>

<p>Only if <code>method="E_RM"</code> or <code>method="E_ER"</code>, the stopping critetion parameter in the iterative Huber regression algorithm. The default is <code class="reqn">10^{-4} \times Tp_1 p_2</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>method="P"</code>, the number of factors <code class="reqn">k_1</code> and <code class="reqn">k_2</code> are estimated by </p>
<p style="text-align: center;"><code class="reqn">\hat{k}_1 = \arg \max_{j \leq k_{max}} \frac{\lambda _j (\bold{M}_c^w)}{\lambda _{j+1} (\bold{M}_c^w)}, \hat{k}_2 = \arg \max_{j \leq k_{max}} \frac{\lambda _j (\bold{M}_r^w)}{\lambda _{j+1} (\bold{M}_r^w)},</code>
</p>
<p> where <code class="reqn">k_{max}</code> is a predetermined value larger than <code class="reqn">k_1</code> and <code class="reqn">k_2</code>. <code class="reqn">\lambda _j(\cdot)</code> is the j-th largest eigenvalue of a nonnegative definitive matrix. See the function <code>MHFA</code> for the definition of <code class="reqn">\bold{M}_c^w</code> and <code class="reqn">\bold{M}_r^w</code>. For details, see He et al. (2023).
</p>
<p>Define <code class="reqn">D=\min({\sqrt{Tp_1}},\sqrt{Tp_2},\sqrt{p_1 p_2})</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{\bold{\Sigma}}_1=\frac{1}{T}\sum_{t=1}^T\hat{\bold{F}}_t \hat{\bold{F}}_t^\top, \hat{\bold{\Sigma}}_2=\frac{1}{T}\sum_{t=1}^T\hat{\bold{F}}_t^\top \hat{\bold{F}}_t,</code>
</p>

<p>where <code class="reqn">\hat{\bold{F}}_t, t=1, \dots, T</code> is estimated by IHR under the number of factor is <code class="reqn">k_{max}</code>.
</p>
<p>If <code>method="E_RM"</code>, the number of factors <code class="reqn">k_1</code> and <code class="reqn">k_2</code> are estimated by </p>
<p style="text-align: center;"><code class="reqn">\hat{k}_1=\sum_{i=1}^{k_{max}}I\left(\mathrm{diag}(\hat{\bold{\Sigma}}_1)&gt;P_1\right), \hat{k}_2=\sum_{j=1}^{k_{max}}I\left(\mathrm{diag}(\hat{\bold{\Sigma}}_2) &gt; P_2\right),</code>
</p>

<p>where <code class="reqn">I</code> is the indicator function. In practice, <code class="reqn">P_1</code> is set as <code class="reqn">\max \left(\mathrm{diag}(\hat{\bold{\Sigma}}_1)\right) \cdot D^{-2/3}</code>, <code class="reqn">P_2</code> is set as <code class="reqn">\max \left(\mathrm{diag}(\hat{\bold{\Sigma}}_2)\right) \cdot D^{-2/3}</code>.
</p>
<p>If <code>method="E_ER"</code>, the number of factors <code class="reqn">k_1</code> and <code class="reqn">k_2</code> are estimated by </p>
<p style="text-align: center;"><code class="reqn">\hat{k}_1 = \arg \max_{i \leq k_{max}} \frac{\lambda _i (\hat{\bold{\Sigma}}_1)}{\lambda _{i+1} (\hat{\bold{\Sigma}}_1)+cD^{-2}}, \hat{k}_2 = \arg \max_{j \leq k_{max}} \frac{\lambda _j (\hat{\bold{\Sigma}}_2)}{\lambda _{j+1} (\hat{\bold{\Sigma}}_2)+cD^{-2}}.</code>
</p>



<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code><code class="reqn">k_1</code></code></td>
<td>
<p>The estimated row factor number.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code><code class="reqn">k_2</code></code></td>
<td>
<p>The estimated column factor number.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yong He, Changwei Zhao, Ran Zhao.
</p>


<h3>References</h3>

<p>He, Y., Kong, X., Yu, L., Zhang, X., &amp; Zhao, C. (2023). Matrix factor analysis: From least squares to iterative projection. Journal of Business &amp; Economic Statistics, 1-26.
</p>
<p>He, Y., Kong, X. B., Liu, D., &amp; Zhao, R. (2023). Robust Statistical Inference for Large-dimensional Matrix-valued Time Series via Iterative Huber Regression. &lt;arXiv:2306.03317&gt;.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(11111)
   T=20;p1=20;p2=20;k1=3;k2=3
   R=matrix(runif(p1*k1,min=-1,max=1),p1,k1)
   C=matrix(runif(p2*k2,min=-1,max=1),p2,k2)
   X=array(0,c(T,p1,p2))
   Y=X;E=Y
   F=array(0,c(T,k1,k2))
   for(t in 1:T){
     F[t,,]=matrix(rnorm(k1*k2),k1,k2)
     E[t,,]=matrix(rnorm(p1*p2),p1,p2)
     Y[t,,]=R%*%F[t,,]%*%t(C)
   }
   X=Y+E
   
   KMHFA(X, kmax=6, method="P")
   
   KMHFA(X, W1 = NULL, W2 = NULL, 6, "E_RM")
   KMHFA(X, W1 = NULL, W2 = NULL, 6, "E_ER")
   
</code></pre>


</div>