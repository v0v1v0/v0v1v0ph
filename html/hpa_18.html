<div class="container">

<table style="width: 100%;"><tr>
<td>hpaBinary</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Semi-nonparametric single index binary choice model estimation</h2>

<h3>Description</h3>

<p>This function performs semi-nonparametric (SNP) maximum 
likelihood estimation of single index binary choice model 
using Hermite polynomial based approximating function proposed by Gallant 
and Nychka in 1987. Please, see <code>dhpa</code> 'Details' section to 
get more information concerning this approximating function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">hpaBinary(
  formula,
  data,
  K = 1L,
  mean_fixed = NA_real_,
  sd_fixed = NA_real_,
  constant_fixed = 0,
  coef_fixed = TRUE,
  is_x0_probit = TRUE,
  is_sequence = FALSE,
  x0 = numeric(0),
  cov_type = "sandwich",
  boot_iter = 100L,
  is_parallel = FALSE,
  opt_type = "optim",
  opt_control = NULL,
  is_validation = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>an object of class "formula" 
(or one that can be coerced to that class):
a symbolic description of the model to be fitted.
All variables in <code>formula</code> should be numeric 
vectors of the same length.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data frame containing the variables in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>non-negative integer representing polynomial degree (order).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean_fixed</code></td>
<td>
<p>numeric value for binary choice 
equation random error density mean parameter. 
Set it to <code>NA</code> (default) if this parameter should be 
estimated rather than fixed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sd_fixed</code></td>
<td>
<p>numeric value for binary choice equation random error
density <code>sd</code> parameter. Set it to <code>NA</code> (default) if this parameter
should be estimated rather than fixed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>constant_fixed</code></td>
<td>
<p>numeric value for binary choice 
equation constant parameter. Set it to <code>NA</code> (default) if this 
parameter should be estimated rather than fixed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef_fixed</code></td>
<td>
<p>logical value indicating whether binary 
equation first independent variable coefficient should be fixed 
(<code>TRUE</code>) or estimated (<code>FALSE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is_x0_probit</code></td>
<td>
<p>logical; if <code>TRUE</code> (default) then initial
points for optimization routine will be
obtained by probit model estimated via glm function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is_sequence</code></td>
<td>
<p>if TRUE then function calculates models with polynomial
degrees from 0 to K each time using initial values obtained from the 
previous step. In this case function will return the list of models where 
i-th list element correspond to model calculated under K=(i-1).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x0</code></td>
<td>
<p>numeric vector of optimization routine initial values.
Note that <code>x0 = c(pol_coefficients[-1], mean, sd, coefficients)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov_type</code></td>
<td>
<p>character determining the type of covariance matrix to be
returned and used for summary. If <code>cov_type = "hessian"</code> then negative
inverse of Hessian matrix will be applied. If <code>cov_type = "gop"</code> then
inverse of Jacobian outer products will be used.
If <code>cov_type = "sandwich"</code> (default) then sandwich covariance matrix
estimator will be applied. If <code>cov_type = "bootstrap"</code> then bootstrap
with <code>boot_iter</code> iterations will be used.
If <code>cov_type = "hessianFD"</code> or <code>cov_type = "sandwichFD"</code> then
(probably) more accurate but computationally demanding central difference 
Hessian approximation will be calculated for the inverse Hessian and 
sandwich estimators correspondingly. Central differences are computed via
analytically provided gradient. This Hessian matrix estimation approach
seems to be less accurate than BFGS approximation if polynomial order
is high (usually greater then 5).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>boot_iter</code></td>
<td>
<p>the number of bootstrap iterations
for <code>cov_type = "bootstrap"</code> covariance matrix estimator type.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is_parallel</code></td>
<td>
<p>if <code>TRUE</code> then multiple cores will be
used for some calculations. It usually provides speed advantage for
large enough samples (about more than 1000 observations).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt_type</code></td>
<td>
<p>string value determining the type of the optimization
routine to be applied. The default is <code>"optim"</code> meaning that BFGS method
from the <code>optim</code> function will be applied.
If <code>opt_type = "GA"</code> then <code>ga</code> function will be
additionally applied.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>opt_control</code></td>
<td>
<p>a list containing arguments to be passed to the
optimization routine depending on <code>opt_type</code> argument value.
Please see details to get additional information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is_validation</code></td>
<td>
<p>logical value indicating whether function input 
arguments should be validated.  Set it to <code>FALSE</code> for slight
performance boost (default value is <code>TRUE</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Densities Hermite polynomial approximation approach has been
proposed by A. Gallant and D. W. Nychka in 1987. The main idea is to
approximate unknown distribution density with scaled Hermite polynomial.
For more information please refer to the literature listed below.
</p>
<p>Let's use notations introduced in <code>dhpa</code> 'Details' 
section. Function <code>hpaBinary</code> maximizes the following
quasi log-likelihood function:
</p>
<p style="text-align: center;"><code class="reqn">\ln L(\gamma_{0}, \gamma, \alpha, \mu, \sigma; x) = 
\sum\limits_{i:z_{i}=1} 
\ln\left(\overline{F}_{\xi}
(-(\gamma_{0}+\gamma x_{i}), \infty;\alpha, \mu, \sigma)\right) +</code>
</p>

<p style="text-align: center;"><code class="reqn">
+\sum\limits_{i:z_{i}=0} 
\ln\left(\overline{F}_{\xi}
(-\infty, -(\gamma_{0} + x_{i}\gamma);\alpha, \mu, \sigma)\right),</code>
</p>

<p>where (in addition to previously defined notations):
</p>
<p><code class="reqn">x_{i}</code> - is row vector of regressors derived from <code>data</code> 
according to <code>formula</code>.
</p>
<p><code class="reqn">\gamma</code> - is column vector of regression coefficients.
</p>
<p><code class="reqn">\gamma_{0}</code> - constant.
</p>
<p><code class="reqn">z_{i}</code> - binary (0 or 1) dependent variable defined in <code>formula</code>.
</p>
<p>Note that <code class="reqn">\xi</code> is one dimensional and <code>K</code> corresponds
to <code class="reqn">K=K_{1}</code>.
</p>
<p>The first polynomial coefficient (zero powers) 
set to 1 for identification purposes i.e. <code class="reqn">\alpha_{0}=1</code>.
</p>
<p>If <code>coef_fixed</code> is <code>TRUE</code> then the coefficient for the 
first independent variable in <code>formula</code> will be fixed to 1 i.e.
<code class="reqn">\gamma_{1}=1</code>.
</p>
<p>If <code>mean_fixed</code> is not <code>NA</code> then <code class="reqn">\mu</code>=<code>mean_fixed</code>
fixed.
</p>
<p>If <code>sd_fixed</code> is not <code>NA</code> then <code class="reqn">\sigma</code>=<code>mean_fixed</code>
fixed. However if <code>is_x0_probit = TRUE</code> then parameter <code class="reqn">\sigma</code> will 
be scale adjusted in order to provide better initial point for optimization 
routine. Please, extract <code class="reqn">\sigma</code> adjusted value from the function's 
output list. The same is for <code>mean_fixed</code>.
</p>
<p>Rows in <code>data</code> corresponding to variables mentioned in <code>formula</code>
which have at least one <code>NA</code> value will be ignored.
</p>
<p>All variables mentioned in <code>formula</code> should be numeric vectors.
</p>
<p>The function calculates standard errors via sandwich estimator
and significance levels are reported taking into account quasi maximum
likelihood estimator (QMLE) asymptotic normality. If one wants to switch
from QMLE to semi-nonparametric estimator (SNPE) during hypothesis testing
then covariance matrix should be estimated again using bootstrap.
</p>
<p>This function maximizes (quasi) log-likelihood function 
via <code>optim</code> function setting its <code>method</code> 
argument to "BFGS". If <code>opt_type = "GA"</code> then genetic
algorithm from <code>ga</code> function
will be additionally (after <code>optim</code> putting its
solution (<code>par</code>) into <code>suggestions</code> matrix) applied in order to 
perform global optimization. Note that global optimization takes
much more time (usually minutes but sometimes hours or even days). 
The number of iterations and population size of the genetic algorithm
will grow linearly along with the number of estimated parameters. 
If it seems that global maximum has not been found then it
is possible to continue the search restarting the function setting 
its input argument <code>x0</code> to <code>x1</code> output value. Note that
if <code>cov_type = "bootstrap"</code> then <code>ga</code>
function will not be used for bootstrap iterations since it
may be extremely time consuming.
</p>
<p>If <code>opt_type = "GA"</code> then <code>opt_control</code> should be the
list containing the values to be passed to <code>ga</code>
function. It is possible to pass arguments <code>lower</code>, <code>upper</code>,
<code>popSize</code>, <code>pcrossover</code>, <code>pmutation</code>, <code>elitism</code>,
<code>maxiter</code>, <code>suggestions</code>, <code>optim</code>, <code>optimArgs</code>,
<code>seed</code> and <code>monitor</code>. 
Note that it is possible to set <code>population</code>,
<code>selection</code>, <code>crossover</code> and <code>mutation</code> arguments changing
<code>ga</code> default parameters via <code>gaControl</code> 
function. These arguments information reported in <code>ga</code>.
In order to provide manual values for <code>lower</code> and <code>upper</code> bounds
please follow parameters ordering mentioned above for the
<code>x0</code> argument. If these bounds are not provided manually then
they (except those related to the polynomial coefficients)
will depend on the estimates obtained
by local optimization via <code>optim</code> function
(this estimates will be in the middle
between <code>lower</code> and <code>upper</code>).
Specifically for each sd parameter <code>lower</code> (<code>upper</code>) bound
is 5 times lower (higher) than this
parameter <code>optim</code> estimate.
For each mean and regression coefficient parameter its lower and 
upper bounds deviate from corresponding <code>optim</code> estimate
by two absolute values of this estimate.
Finally, lower and upper bounds for each polynomial
coefficient are <code>-10</code> and <code>10</code> correspondingly (do not depend
on their <code>optim</code> estimates).
</p>
<p>The following arguments are differ from their defaults in
<code>ga</code>:
</p>

<ul>
<li> <p><code>pmutation = 0.2</code>,
</p>
</li>
<li> <p><code>optim = TRUE</code>,
</p>
</li>
<li> <p><code>optimArgs =
list("method" = "Nelder-Mead", "poptim" = 0.2, "pressel" = 0.5)</code>,
</p>
</li>
<li> <p><code>seed = 8</code>,
</p>
</li>
<li> <p><code>elitism = 2 + round(popSize * 0.1)</code>.</p>
</li>
</ul>
<p>Let's denote by <code>n_reg</code> the number of regressors
included into the <code>formula</code>.
The arguments <code>popSize</code> and <code>maxiter</code> of
<code>ga</code> function have been set proportional to the number of
estimated polynomial coefficients and independent variables:
</p>

<ul>
<li> <p><code>popSize = 10 + 5 * (K + 1) + 2 * n_reg</code>
</p>
</li>
<li> <p><code>maxiter = 50 * (1 + K) + 10 * n_reg</code></p>
</li>
</ul>
<h3>Value</h3>

<p>This function returns an object of class "hpaBinary".<br><br>
An object of class "hpaBinary" is a list containing the 
following components:
</p>

<ul>
<li> <p><code>optim</code> - <code>optim</code> function output. 
If <code>opt_type = "GA"</code> then it is the list containing 
<code>optim</code> and <code>ga</code> functions outputs.
</p>
</li>
<li> <p><code>x1</code> - numeric vector of distribution parameters estimates.
</p>
</li>
<li> <p><code>mean</code> - mean (mu) parameter of density function estimate.
</p>
</li>
<li> <p><code>sd</code> - sd (sigma) parameter of density function estimate.
</p>
</li>
<li> <p><code>pol_coefficients</code> - polynomial coefficients estimates.
</p>
</li>
<li> <p><code>pol_degrees</code> - the same as <code>K</code> input parameter.
</p>
</li>
<li> <p><code>coefficients</code> - regression (single index) 
coefficients estimates.
</p>
</li>
<li> <p><code>cov_mat</code> - covariance matrix estimate.
</p>
</li>
<li> <p><code>marginal_effects</code> - marginal effects matrix where columns are
variables and rows are observations.
</p>
</li>
<li> <p><code>results</code> - numeric matrix representing estimation results.
</p>
</li>
<li> <p><code>log-likelihood</code> - value of Log-Likelihood function.
</p>
</li>
<li> <p><code>AIC</code> - AIC value.
</p>
</li>
<li> <p><code>errors_exp</code> - random error expectation estimate.
</p>
</li>
<li> <p><code>errors_var</code> - random error variance estimate.
</p>
</li>
<li> <p><code>dataframe</code> - data frame containing variables mentioned in 
<code>formula</code> without <code>NA</code> values.
</p>
</li>
<li> <p><code>model_Lists</code> - lists containing information about 
fixed parameters and parameters indexes in <code>x1</code>.
</p>
</li>
<li> <p><code>n_obs</code> - number of observations.
</p>
</li>
<li> <p><code>z_latent</code> - latent variable (single index) estimates.
</p>
</li>
<li> <p><code>z_prob</code> - probabilities of positive 
outcome (i.e. 1) estimates.</p>
</li>
</ul>
<h3>References</h3>

<p>A. Gallant and D. W. Nychka (1987) &lt;doi:10.2307/1913241&gt;
</p>


<h3>See Also</h3>

<p>summary.hpaBinary, predict.hpaBinary, 
plot.hpaBinary,
logLik.hpaBinary
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Estimate survival probability on Titanic

library("titanic")

# Prepare data set converting  
# all variables to numeric vectors
h &lt;- data.frame("male" = as.numeric(titanic_train$Sex == "male"))
	h$class_1 &lt;- as.numeric(titanic_train$Pclass == 1)
	h$class_2 &lt;- as.numeric(titanic_train$Pclass == 2)
	h$class_3 &lt;- as.numeric(titanic_train$Pclass == 3)
	h$sibl &lt;- titanic_train$SibSp
	h$survived &lt;- titanic_train$Survived
	h$age &lt;- titanic_train$Age
	h$parch &lt;- titanic_train$Parch
	h$fare &lt;- titanic_train$Fare
	
# Estimate model parameters
model_hpa_1 &lt;- hpaBinary(survived ~class_1 + class_2 +
	male + age + sibl + parch + fare,
	K = 3, data = h)
#get summary
summary(model_hpa_1)

# Get predicted probabilities
pred_hpa_1 &lt;- predict(model_hpa_1)

# Calculate number of correct predictions
hpa_1_correct_0 &lt;- sum((pred_hpa_1 &lt; 0.5) &amp; 
                       (model_hpa_1$dataframe$survived == 0))
hpa_1_correct_1 &lt;- sum((pred_hpa_1 &gt;= 0.5) &amp; 
                       (model_hpa_1$dataframe$survived == 1))
hpa_1_correct &lt;- hpa_1_correct_1 + hpa_1_correct_0

# Plot random errors density approximation
plot(model_hpa_1)



## Estimate parameters on data simulated from Student distribution

library("mvtnorm")
set.seed(123)

# Simulate independent variables from normal distribution
n &lt;- 5000
X &lt;- rmvnorm(n=n, mean = c(0,0), 
sigma = matrix(c(1,0.5,0.5,1), ncol=2))

# Simulate random errors from Student distribution
epsilon &lt;- rt(n, 5) * (3 / sqrt(5))

# Calculate latent and observable variables values
z_star &lt;- 1 + X[, 1] + X[, 2] + epsilon
z &lt;- as.numeric((z_star &gt; 0))

# Store the results into data frame
h &lt;- as.data.frame(cbind(z,X))
names(h) &lt;- c("z", "x1", "x2")

# Estimate model parameters
model &lt;- hpaBinary(formula = z ~ x1 + x2, data=h, K = 3)
summary(model)

# Get predicted probabilities of 1 values
predict(model)

# Plot density function approximation
plot(model)



</code></pre>


</div>