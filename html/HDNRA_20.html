<div class="container">

<table style="width: 100%;"><tr>
<td>tsbf_zzz2023</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Test proposed by Zhang et al. (2023)</h2>

<h3>Description</h3>

<p>Zhang et al. (2023)'s test for testing equality of two-sample high-dimensional mean vectors without assuming that two covariance matrices are the same.
</p>


<h3>Usage</h3>

<pre><code class="language-R">tsbf_zzz2023(y1, y2, cutoff)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y1</code></td>
<td>
<p>The data matrix (p by n1) from the first population. Each column represents a <code class="reqn">p</code>-dimensional observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y2</code></td>
<td>
<p>The data matrix (p by n2) from the first population. Each column represents a <code class="reqn">p</code>-dimensional observation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cutoff</code></td>
<td>
<p>An empirical criterion for applying the adjustment coefficient</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Suppose we have two independent high-dimensional samples:
</p>
<p style="text-align: center;"><code class="reqn">
\boldsymbol{y}_{i1},\ldots,\boldsymbol{y}_{in_i}, \;\operatorname{are \; i.i.d. \; with}\; \operatorname{E}(\boldsymbol{y}_{i1})=\boldsymbol{\mu}_i,\; \operatorname{Cov}(\boldsymbol{y}_{i1})=\boldsymbol{\Sigma}_i,i=1,2.
</code>
</p>

<p>The primary object is to test
</p>
<p style="text-align: center;"><code class="reqn">H_{0}: \boldsymbol{\mu}_1 = \boldsymbol{\mu}_2\; \operatorname{versus}\; H_{1}: \boldsymbol{\mu}_1 \neq \boldsymbol{\mu}_2.</code>
</p>

<p>Zhang et al.(2023) proposed the following test statistic:
</p>
<p style="text-align: center;"><code class="reqn">T_{ZZZ}=\frac{n_1 n_2}{np}(\bar{\boldsymbol{y}}_1-\bar{\boldsymbol{y}}_2)^{\top} \hat{\boldsymbol{D}}_n^{-1}(\bar{\boldsymbol{y}}_1-\bar{\boldsymbol{y}}_2),</code>
</p>

<p>where <code class="reqn">\bar{\boldsymbol{y}}_{i},i=1,2</code> are the sample mean vectors, and <code class="reqn">\hat{\boldsymbol{D}}_n=\operatorname{diag}(\hat{\boldsymbol{\Sigma}}_1/n+\hat{\boldsymbol{\Sigma}}_2/n)</code> with <code class="reqn">n=n_1+n_2</code>.
They showed that under the null hypothesis, <code class="reqn">T_{ZZZ}</code> and a chi-squared-type mixture have the same limiting distribution.
</p>


<h3>Value</h3>

<p>A  (list) object of  <code>S3</code> class <code>htest</code>  containing the following elements:
</p>

<dl>
<dt>p.value</dt>
<dd>
<p>the p-value of the test proposed by Zhang et al. (2023)'s test.</p>
</dd>
<dt>statistic</dt>
<dd>
<p>the test statistic proposed by Zhang et al. (2023)'s test.</p>
</dd>
<dt>df</dt>
<dd>
<p>estimated approximate degrees of freedom of Zhang et al. (2023)'s test.</p>
</dd>
<dt>cpn</dt>
<dd>
<p>the adjustment coefficient used in Zhang et al. (2023)'s test.</p>
</dd>
</dl>
<h3>References</h3>

<p>Zhang L, Zhu T, Zhang J (2023).
“Two-sample Behrens–Fisher problems for high-dimensional data: a normal reference scale-invariant test.”
<em>Journal of Applied Statistics</em>, <b>50</b>(3), 456–476.
<a href="https://doi.org/10.1080/02664763.2020.1834516">doi:10.1080/02664763.2020.1834516</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1234)
n1 &lt;- 20
n2 &lt;- 30
p &lt;- 50
mu1 &lt;- t(t(rep(0, p)))
mu2 &lt;- mu1
rho1 &lt;- 0.1
rho2 &lt;- 0.2
a1 &lt;- 1
a2 &lt;- 2
w1 &lt;- (-2 * sqrt(a1 * (1 - rho1)) + sqrt(4 * a1 * (1 - rho1) + 4 * p * a1 * rho1)) / (2 * p)
x1 &lt;- w1 + sqrt(a1 * (1 - rho1))
Gamma1 &lt;- matrix(rep(w1, p * p), nrow = p)
diag(Gamma1) &lt;- rep(x1, p)
w2 &lt;- (-2 * sqrt(a2 * (1 - rho2)) + sqrt(4 * a2 * (1 - rho2) + 4 * p * a2 * rho2)) / (2 * p)
x2 &lt;- w2 + sqrt(a2 * (1 - rho2))
Gamma2 &lt;- matrix(rep(w2, p * p), nrow = p)
diag(Gamma2) &lt;- rep(x2, p)
Z1 &lt;- matrix(rnorm(n1*p,mean = 0,sd = 1), p, n1)
Z2 &lt;- matrix(rnorm(n2*p,mean = 0,sd = 1), p, n2)
y1 &lt;- Gamma1 %*% Z1 + mu1%*%(rep(1,n1))
y2 &lt;- Gamma2 %*% Z2 + mu2%*%(rep(1,n2))
tsbf_zzz2023(y1,y2,cutoff=1.2)

</code></pre>


</div>