<div class="container">

<table style="width: 100%;"><tr>
<td>h2_overall</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Overall Interaction Strength</h2>

<h3>Description</h3>

<p>Friedman and Popescu's statistic of overall interaction strength per
feature, see Details. Use <code>plot()</code> to get a barplot.
</p>


<h3>Usage</h3>

<pre><code class="language-R">h2_overall(object, ...)

## Default S3 method:
h2_overall(object, ...)

## S3 method for class 'hstats'
h2_overall(
  object,
  normalize = TRUE,
  squared = TRUE,
  sort = TRUE,
  zero = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object of class "hstats".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Currently unused.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>normalize</code></td>
<td>
<p>Should statistics be normalized? Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>squared</code></td>
<td>
<p>Should <em>squared</em> statistics be returned? Default is <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sort</code></td>
<td>
<p>Should results be sorted? Default is <code>TRUE</code>.
(Multi-output is sorted by row means.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zero</code></td>
<td>
<p>Should rows with all 0 be shown? Default is <code>TRUE</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The logic of Friedman and Popescu (2008) is as follows:
If there are no interactions involving feature <code class="reqn">x_j</code>, we can decompose the
(centered) prediction function <code class="reqn">F</code> into the sum of the (centered) partial
dependence <code class="reqn">F_j</code> on <code class="reqn">x_j</code> and the (centered) partial dependence
<code class="reqn">F_{\setminus j}</code> on all other features <code class="reqn">\mathbf{x}_{\setminus j}</code>, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">
  F(\mathbf{x}) = F_j(x_j) + F_{\setminus j}(\mathbf{x}_{\setminus j}).
</code>
</p>

<p>Correspondingly, Friedman and Popescu's statistic of overall interaction
strength of <code class="reqn">x_j</code> is given by
</p>
<p style="text-align: center;"><code class="reqn">
  H_j^2 = \frac{\frac{1}{n} \sum_{i = 1}^n\big[F(\mathbf{x}_i) - 
  \hat F_j(x_{ij}) - \hat F_{\setminus j}(\mathbf{x}_{i\setminus j})
  \big]^2}{\frac{1}{n} \sum_{i = 1}^n\big[F(\mathbf{x}_i)\big]^2}
</code>
</p>

<p>(check <code>partial_dep()</code> for all definitions).
</p>
<p><strong>Remarks:</strong>
</p>

<ol>
<li>
<p> Partial dependence functions (and <code class="reqn">F</code>) are all centered to
(possibly weighted) mean 0.
</p>
</li>
<li>
<p> Partial dependence functions (and <code class="reqn">F</code>) are evaluated over the data distribution.
This is different to partial dependence plots, where one uses a fixed grid.
</p>
</li>
<li>
<p> Weighted versions follow by replacing all arithmetic means by corresponding
weighted means.
</p>
</li>
<li>
<p> Multivariate predictions can be treated in a component-wise manner.
</p>
</li>
<li>
<p> Due to (typically undesired) extrapolation effects of partial dependence functions,
depending on the model, values above 1 may occur.
</p>
</li>
<li> <p><code class="reqn">H^2_j = 0</code> means there are no interactions associated with <code class="reqn">x_j</code>.
The higher the value, the more prediction variability comes from interactions
with <code class="reqn">x_j</code>.
</p>
</li>
<li>
<p> Since the denominator is the same for all features, the values of the test
statistics can be compared across features.
</p>
</li>
</ol>
<h3>Value</h3>

<p>An object of class "hstats_matrix" containing these elements:
</p>

<ul>
<li> <p><code>M</code>: Matrix of statistics (one column per prediction dimension), or <code>NULL</code>.
</p>
</li>
<li> <p><code>SE</code>: Matrix with standard errors of <code>M</code>, or <code>NULL</code>.
Multiply with <code>sqrt(m_rep)</code> to get <em>standard deviations</em> instead.
Currently, supported only for <code>perm_importance()</code>.
</p>
</li>
<li> <p><code>m_rep</code>: The number of repetitions behind standard errors <code>SE</code>, or <code>NULL</code>.
Currently, supported only for <code>perm_importance()</code>.
</p>
</li>
<li> <p><code>statistic</code>: Name of the function that generated the statistic.
</p>
</li>
<li> <p><code>description</code>: Description of the statistic.
</p>
</li>
</ul>
<h3>Methods (by class)</h3>


<ul>
<li> <p><code>h2_overall(default)</code>: Default method of overall interaction strength.
</p>
</li>
<li> <p><code>h2_overall(hstats)</code>: Overall interaction strength from "hstats" object.
</p>
</li>
</ul>
<h3>References</h3>

<p>Friedman, Jerome H., and Bogdan E. Popescu. <em>"Predictive Learning via Rule Ensembles."</em>
The Annals of Applied Statistics 2, no. 3 (2008): 916-54.
</p>


<h3>See Also</h3>

<p><code>hstats()</code>, <code>h2()</code>, <code>h2_pairwise()</code>, <code>h2_threeway()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># MODEL 1: Linear regression
fit &lt;- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
s &lt;- hstats(fit, X = iris[, -1])
h2_overall(s)
plot(h2_overall(s))

# MODEL 2: Multi-response linear regression
fit &lt;- lm(as.matrix(iris[, 1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
s &lt;- hstats(fit, X = iris[, 3:5], verbose = FALSE)
plot(h2_overall(s, zero = FALSE))
</code></pre>


</div>