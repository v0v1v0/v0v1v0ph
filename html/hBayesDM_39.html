<div class="container">

<table style="width: 100%;"><tr>
<td>hBayesDM-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Hierarchical Bayesian Modeling of Decision-Making Tasks</h2>

<h3>Description</h3>

<p>Fit an array of decision-making tasks with computational models in a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of various computational models with a single line of coding.
Bolded tasks, followed by their respective models, are itemized below.
</p>

<dl>
<dt><strong>Bandit</strong></dt>
<dd>
<p>2-Armed Bandit (Rescorla-Wagner (delta)) — bandit2arm_delta <br>
4-Armed Bandit with fictive updating + reward/punishment sensitvity (Rescorla-Wagner (delta)) — bandit4arm_4par <br>
4-Armed Bandit with fictive updating + reward/punishment sensitvity + lapse (Rescorla-Wagner (delta)) — bandit4arm_lapse</p>
</dd>
<dt><strong>Bandit2</strong></dt>
<dd>
<p>Kalman filter — bandit4arm2_kalman_filter</p>
</dd>
<dt><strong>Cambridge Gambling Task</strong></dt>
<dd>
<p>Cumulative Model — cgt_cm</p>
</dd>
<dt><strong>Choice RT</strong></dt>
<dd>
<p>Drift Diffusion Model — choiceRT_ddm <br>
Drift Diffusion Model for a single subject — choiceRT_ddm_single <br>
Linear Ballistic Accumulator (LBA) model — choiceRT_lba <br>
Linear Ballistic Accumulator (LBA) model for a single subject — choiceRT_lba_single</p>
</dd>
<dt><strong>Choice under Risk and Ambiguity</strong></dt>
<dd>
<p>Exponential model — cra_exp <br>
Linear model — cra_linear</p>
</dd>
<dt><strong>Description-Based Decision Making</strong></dt>
<dd>
<p>probability weight function — dbdm_prob_weight</p>
</dd>
<dt><strong>Delay Discounting</strong></dt>
<dd>
<p>Constant Sensitivity — dd_cs <br>
Constant Sensitivity for a single subject — dd_cs_single <br>
Exponential — dd_exp <br>
Hyperbolic — dd_hyperbolic <br>
Hyperbolic for a single subject — dd_hyperbolic_single</p>
</dd>
<dt><strong>Orthogonalized Go/Nogo</strong></dt>
<dd>
<p>RW + Noise — gng_m1 <br>
RW + Noise + Bias — gng_m2 <br>
RW + Noise + Bias + Pavlovian Bias — gng_m3 <br>
RW(modified) + Noise + Bias + Pavlovian Bias — gng_m4</p>
</dd>
<dt><strong>Iowa Gambling</strong></dt>
<dd>
<p>Outcome-Representation Learning — igt_orl <br>
Prospect Valence Learning-DecayRI — igt_pvl_decay <br>
Prospect Valence Learning-Delta — igt_pvl_delta <br>
Value-Plus_Perseverance — igt_vpp</p>
</dd>
<dt><strong>Peer influence task</strong></dt>
<dd>
<p>OCU model — peer_ocu</p>
</dd>
<dt><strong>Probabilistic Reversal Learning</strong></dt>
<dd>
<p>Experience-Weighted Attraction — prl_ewa <br>
Fictitious Update — prl_fictitious <br>
Fictitious Update w/o alpha (indecision point) — prl_fictitious_woa <br>
Fictitious Update and multiple blocks per subject — prl_fictitious_multipleB <br>
Reward-Punishment — prl_rp <br>
Reward-Punishment and multiple blocks per subject — prl_rp_multipleB <br>
Fictitious Update with separate learning for Reward-Punishment — prl_fictitious_rp <br>
Fictitious Update with separate learning for Reward-Punishment w/o alpha (indecision point) — prl_fictitious_rp_woa</p>
</dd>
<dt><strong>Probabilistic Selection Task</strong></dt>
<dd>
<p>Q-learning with two learning rates — pst_gainloss_Q</p>
</dd>
<dt><strong>Risk Aversion</strong></dt>
<dd>
<p>Prospect Theory (PT) — ra_prospect <br>
PT without a loss aversion parameter — ra_noLA <br>
PT without a risk aversion parameter — ra_noRA</p>
</dd>
<dt><strong>Risky Decision Task</strong></dt>
<dd>
<p>Happiness model — rdt_happiness</p>
</dd>
<dt><strong>Two-Step task</strong></dt>
<dd>
<p>Full model (7 parameters) — ts_par7 <br>
6 parameter model (without eligibility trace, lambda) — ts_par6 <br>
4 parameter model — ts_par4</p>
</dd>
<dt><strong>Ultimatum Game</strong></dt>
<dd>
<p>Ideal Bayesian Observer — ug_bayes <br>
Rescorla-Wagner (delta) — ug_delta</p>
</dd>
</dl>
<h3>Author(s)</h3>

<p>Woo-Young Ahn <a href="mailto:wahn55@snu.ac.kr">wahn55@snu.ac.kr</a>
</p>
<p>Nathaniel Haines <a href="mailto:haines.175@osu.edu">haines.175@osu.edu</a>
</p>
<p>Lei Zhang <a href="mailto:bnuzhanglei2008@gmail.com">bnuzhanglei2008@gmail.com</a>
</p>


<h3>References</h3>

<p>Please cite as:
Ahn, W.-Y., Haines, N., &amp; Zhang, L. (2017). Revealing neuro-computational mechanisms of reinforcement learning and decision-making with the hBayesDM package. <em>Computational Psychiatry</em>. 1, 24-57. https://doi.org/10.1162/CPSY_a_00002
</p>


<h3>See Also</h3>

<p>For tutorials and further readings, visit : <a href="http://rpubs.com/CCSL/hBayesDM">http://rpubs.com/CCSL/hBayesDM</a>.
</p>


</div>