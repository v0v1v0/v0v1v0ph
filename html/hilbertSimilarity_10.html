<div class="container">

<table style="width: 100%;"><tr>
<td>js.dist</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute the Jensen-Shannon Distance between 2 sets of Hilbert Index</h2>

<h3>Description</h3>

<p>The <a href="https://en.wikipedia.org/wiki/Jensen-Shannon_divergence">Jensen-Shannon distance</a> is a method to
measure the distance between discrete probability distributions. To measure the distance between 2 high-dimensional
datasets, we cut the space into sub-cubes, then count the number of events per cube. The resulting probability
distributions can be compared using the Jensen-Shannon distance.
</p>


<h3>Usage</h3>

<pre><code class="language-R">js.dist(mat, pc = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mat</code></td>
<td>
<p>a matrix of counts, where rows correspond to samples and columns to Hilbert index</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pc</code></td>
<td>
<p>a pseudo-count that is added to all samples to avoid divide-by-zero errors</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a S3 distance object
</p>


<h3>Author(s)</h3>

<p>Yann Abraham
</p>


<h3>Examples</h3>

<pre><code class="language-R"># generate 3 samples over 5 dimensions
# sample 1 and 2 are similar, sample 3 has an extra population
# set the seed for reproducible examples
set.seed(1234)
my.samples &lt;- lapply(LETTERS[1:3],function(j) {
    # each sample has a different number of events
    n &lt;- floor(runif(1,0.5,0.8)*10000)
    # matrix is random normal over 5 dimensions
    cur.mat &lt;- matrix(rnorm(5*n),ncol=5)
    # rescale cur.mat to a [0,3] interval
    cur.mat &lt;- 3*(cur.mat-min(cur.mat))/diff(range(cur.mat))
    dimnames(cur.mat)[[2]] &lt;- LETTERS[(length(LETTERS)-4):length(LETTERS)]
    if(j=='C') {
      # select 30% of the points
      cur.rws &lt;- sample(n,round(n*0.3,0))
      # select 2 columns at random
      cur.cls &lt;- sample(ncol(cur.mat),2)
      # create an artificial sub population
      cur.mat[cur.rws,cur.cls] &lt;- 4*cur.mat[cur.rws,cur.cls]
    }
    return(cur.mat)
  }
)
names(my.samples) &lt;- LETTERS[1:3]

# check the population size
lapply(my.samples,nrow)

# assemble a sample matrix
my.samples.mat &lt;- do.call('rbind',my.samples)
my.samples.id &lt;- lapply(names(my.samples),
                        function(cur.spl) rep(cur.spl,nrow(my.samples[[cur.spl]])))
my.samples.id &lt;- unlist(my.samples.id)

# Estimate the maximum required Hilbert order
hilbert.order(my.samples.mat)

# Estimate the cut positions
my.cuts &lt;- make.cut(my.samples.mat,n=5,count.lim=5)

# Visualize the cuts
show.cut(my.cuts)

# Cut the matrix &amp; compute the hilbert index
my.samples.cut &lt;- do.cut(my.samples.mat,my.cuts,type='combined')
system.time(my.samples.index &lt;- do.hilbert(my.samples.cut,horder=4))

# Visualize samples as density plots
my.samples.dens &lt;- density(my.samples.index)
my.samples.dens$y &lt;- (my.samples.dens$y-min(my.samples.dens$y))/diff(range(my.samples.dens$y))

plot(my.samples.dens,col='grey3',lty=2)
ksink &lt;- lapply(names(my.samples),function(cur.spl) {
    cat(cur.spl,'\n')
    cur.dens &lt;- density(my.samples.index[my.samples.id==cur.spl],
                        bw=my.samples.dens$bw)
    cur.dens$y &lt;- (cur.dens$y-min(cur.dens$y))/diff(range(cur.dens$y))
    lines(cur.dens$x,
          cur.dens$y,
          col=match(cur.spl,names(my.samples))+1)
  }
)
legend('topright',
       legend=names(my.samples),
       co=seq(length(my.samples))+1,
       pch=16,
       bty='n' )

# assemble a contingency table
my.samples.table &lt;- table(my.samples.index,my.samples.id)
dim(my.samples.table)

heatmap(log10(my.samples.table+0.00001),
        col=colorRampPalette(c('white',blues9))(24),
        Rowv=NA,Colv=NA,
        scale='none')

# compute the Jensen-Shannon distance
my.samples.dist &lt;- js.dist(t(my.samples.table))
my.samples.clust &lt;- hclust(my.samples.dist)

plot(my.samples.clust)
</code></pre>


</div>